{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras, time, sys, os, gc\n",
    "\n",
    "DTYPE_OP = 'float32'\n",
    "keras.backend.set_floatx(DTYPE_OP)\n",
    "\n",
    "if DTYPE_OP == 'float64':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float64).eps)\n",
    "elif DTYPE_OP == 'float32':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float32).eps)\n",
    "    \n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL Variables\n",
    "BATCH_SIZE = 128 #rodrigues = BATCH_SIZE = 64\n",
    "EPOCHS_BASE = 50\n",
    "OPT = 'adam' #optimizer for neural network \n",
    "TOL = 3e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./data/Sentiment/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(filename):\n",
    "    f = open(filename)\n",
    "    data = [line.strip() for line in f]\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. train texts: 4999\n",
      "Num. test texts:  3999\n"
     ]
    }
   ],
   "source": [
    "texts_train = read_texts(folder+\"Sentiment_text_train.txt\")\n",
    "texts_test  = read_texts(folder+\"Sentiment_text_test.txt\")\n",
    "\n",
    "Z_train = np.loadtxt(folder+\"Sentiment_Z_train.txt\", dtype='int')\n",
    "Z_test  = np.loadtxt(folder+\"Sentiment_Z_test.txt\", dtype='int')\n",
    "\n",
    "print(\"Num. train texts: %d\" % len(texts_train))\n",
    "print(\"Num. test texts:  %d\" % len(texts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14096 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "MAX_NB_WORDS = 14000\n",
    "tokenizer = preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train+texts_test)\n",
    "sequences_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "#MAX_NB_WORDS = len(tokenizer.word_index)\n",
    "print('Found %s unique tokens.' % len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = list(map(len,sequences_train))\n",
    "max_L = np.max(lens)\n",
    "print(\"Real max: \",max_L)\n",
    "max_L = 50 \n",
    "print(\"Used max: \",max_L)\n",
    "\n",
    "X_train = preprocessing.sequence.pad_sequences(sequences_train, maxlen=max_L,dtype='int32', value=0,padding='pre')\n",
    "X_test = preprocessing.sequence.pad_sequences(sequences_test, maxlen=max_L,dtype='int32', value=0,padding='pre')\n",
    "print('Shape of train tensor:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "GLOVE_FILE = \"../GLOVE/glove.6B.%dd.txt\"%(EMBEDDING_DIM)\n",
    "#GLOVE_FILE = \"../AUX_DATA/glove.twitter.27B/glove.twitter.27B.%dd.txt\"%(EMBEDDING_DIM)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE) as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[values[0]] = coefs\n",
    "print('Preparing embedding matrix.')\n",
    "sorted_x = sorted(tokenizer.word_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "vocab = {value[0]:tokenizer.word_index[value[0]] for i, value in enumerate(sorted_x) if i < MAX_NB_WORDS}\n",
    "embedding_matrix = np.zeros((len(vocab)+1, EMBEDDING_DIM))\n",
    "v=0\n",
    "for word, i in vocab.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector # words not found in embedding index will be all-zeros.\n",
    "        v+=1\n",
    "del embeddings_index, sorted_x, tokenizer\n",
    "gc.collect()\n",
    "print(\"Words found on glove: \",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(Z_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AMT data...\n",
      "Remove 0 annotators that do not annotate on this set \n",
      "Shape (data,annotators):  (4999, 203)\n",
      "Classes:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading AMT data...\")\n",
    "y_obs = np.loadtxt(folder+\"answers.txt\",dtype='int16') #not annotation symbol ==-1\n",
    "\n",
    "T_weights = np.sum(y_obs != -1,axis=0) #number of annotations per annotator\n",
    "print(\"Remove %d annotators that do not annotate on this set \"%(np.sum(T_weights==0)))\n",
    "y_obs = y_obs[:,T_weights!=0]\n",
    "T_weights = np.sum(y_obs != -1,axis=0) \n",
    "\n",
    "N,T = y_obs.shape\n",
    "Kl = np.max(y_obs)+1 #asumming classification scenario\n",
    "print(\"Shape (data,annotators): \",(N,T))\n",
    "print(\"Classes: \",Kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum annotations in a example:  4\n",
      "Maximum annotations in a example:  10\n",
      "T data (expected value):  5.550310062012403\n",
      "Graphics of T weights\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWO0lEQVR4nO3db2xc133m8e9jSrIKt46lehLYIrM0Wu4uFQJVjVnbQIhFmLSy5C5WKtAAIoJGiIioC1iECnTXf8oXjpISqI1tXIdwDKhLbZSioiqnrS3E1nq1DouASGNr1MiOJK4hbpRGYwkWGymO40D/f/tijuyhRJEz/DPD0X0+ADEzv3su59wXenh17rn3KCIwM7NsuKXeHTAzs9px6JuZZYhD38wsQxz6ZmYZ4tA3M8uQRfXuwFTuvPPOaG1trXc3zMwaysGDB/81InKTbVvQod/a2kqhUKh3N8zMGoqkf7nRNg/vmJlliEPfzCxDHPpmZhni0DczyxCHvplZhlQc+pKaJP1A0rfT53skvSbpmKS/lbQk1W9Nn8fS9tay3/F4qr8l6cG5PhizWhgaGqKjo4OmpiY6OjoYGhqqd5fMKlbNmf5WYLTs85PA0xHRBpwFelK9BzgbEb8JPJ3aIWklsAH4BLAG+Lqkptl136y2hoaG6OvrY2BggHPnzjEwMEBfX5+D3xpGRaEvqRn4PeB/pM8CPg18KzXZCaxP79elz6Ttn0nt1wG7I+J8RBwHxoD75uIgzGqlv7+fwcFBurq6WLx4MV1dXQwODtLf31/vrplVpNIz/b8EHgGupM+/DvwsIi6lz0VgRXq/AjgBkLa/m9p/UJ9knw9I2iypIKkwPj5exaGYzb/R0VE6Ozsn1Do7OxkdHb3BHmYLy7ShL+k/Aacj4mB5eZKmMc22qfb5sBCxPSLyEZHP5Sa9i9isbtrb2xkZGZlQGxkZob29vU49MqtOJWf6nwT+s6QfA7spDev8JXCHpKuPcWgGTqb3RaAFIG3/CHCmvD7JPmYNoa+vj56eHoaHh7l48SLDw8P09PTQ19dX766ZVWTaZ+9ExOPA4wCSPgX814j4nKTngT+g9IdgI/Bi2mVv+vxPaft3IiIk7QV2SfoqcDfQBrw+t4djNr+6u7sB6O3tZXR0lPb2dvr7+z+omy10s3ng2qPAbkl/BvwAGEz1QeCvJY1ROsPfABARRyTtAY4Cl4CHI+LyLL7frC66u7sd8tawtJAXRs/n8+GnbJqZVUfSwYjIT7bNd+SamWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswypZGH0pZJel/SGpCOStqX6NyQdl3Qo/axKdUn6mqQxSW9Kurfsd22UdCz9bJy/wzIzs8lUslzieeDTEfELSYuBEUn70rb/FhHfuqb9Wkrr37YB9wPPAfdLWg48AeSBAA5K2hsRZ+fiQMzMbHrTnulHyS/Sx8XpZ6o1FtcB30z7fR+4Q9JdwIPA/og4k4J+P7Bmdt03M7NqVDSmL6lJ0iHgNKXgfi1t6k9DOE9LujXVVgAnynYvptqN6td+12ZJBUmF8fHxKg/HzMymUlHoR8TliFgFNAP3SeoAHgf+PfAfgOXAo6m5JvsVU9Sv/a7tEZGPiHwul6uke2ZmVqGqZu9ExM+AfwTWRMSpNIRzHvifwH2pWRFoKdutGTg5Rd3MzGqkktk7OUl3pPe/AvwO8H/TOD2SBKwHDqdd9gKfT7N4HgDejYhTwCvAaknLJC0DVqeamZnVSCWzd+4CdkpqovRHYk9EfFvSdyTlKA3bHAL+S2r/MvAQMAb8EvgCQESckfQV4EBq9+WIODN3h2JmZtNRxFQTceorn89HoVCodzfMzBqKpIMRkZ9sm+/INTPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQypZOWuppNclvSHpiKRtqX6PpNckHZP0t5KWpPqt6fNY2t5a9rseT/W3JD04XwdlZmaTq+RM/zzw6Yj4LWAVsCYtg/gk8HREtAFngZ7Uvgc4GxG/CTyd2iFpJbAB+ASwBvh6Wo3LzMxqZNrQT4uf/yJ9XJx+Avg08K1U30lpnVyAdekzaftn0jq664DdEXE+Io5TWk7x6mLqZmZWAxWN6UtqknQIOA3sB/4f8LOIuJSaFIEV6f0K4ARA2v4u8Ovl9Un2Kf+uzZIKkgrj4+PVH5GZmd1QRaEfEZcjYhXQTOnsvH2yZulVN9h2o/q137U9IvIRkc/lcpV0z8zMKlTV7J2I+Bnwj8ADwB2SFqVNzcDJ9L4ItACk7R8BzpTXJ9nHzMxqoJLZOzlJd6T3vwL8DjAKDAN/kJptBF5M7/emz6Tt34mISPUNaXbPPUAb8PpcHYiZmU1v0fRNuAvYmWba3ALsiYhvSzoK7Jb0Z8APgMHUfhD4a0ljlM7wNwBExBFJe4CjwCXg4Yi4PLeHY2ZmU1HpJHxhyufzUSgU6t0NM7OGIulgROQn2+Y7cs3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhlSyXGKLpGFJo5KOSNqa6l+S9LakQ+nnobJ9Hpc0JuktSQ+W1dek2pikx+bnkMzM7EYqWS7xEvAnEfHPkn4NOChpf9r2dET89/LGklZSWiLxE8DdwP+R9G/T5meB36W0SPoBSXsj4uhcHIiZmU1v2tCPiFPAqfT+PUmjwIopdlkH7I6I88DxtFbufWnbWET8CEDS7tTWoW9mViNVjelLagV+G3gtlbZIelPSDknLUm0FcKJst2Kq3ah+7XdsllSQVBgfH6+me2ZmNo2KQ1/SrwJ/B/xxRPwceA74DWAVpf8J/MXVppPsHlPUJxYitkdEPiLyuVyu0u6ZmVkFKhnTR9JiSoH/NxHx9wAR8U7Z9r8Cvp0+FoGWst2bgZPp/Y3qZmZWA5XM3hEwCIxGxFfL6neVNft94HB6vxfYIOlWSfcAbcDrwAGgTdI9kpZQuti7d24Ow8zMKlHJmf4ngT8EfijpUKr9KdAtaRWlIZofA38EEBFHJO2hdIH2EvBwRFwGkLQFeAVoAnZExJE5PBYzM5uGIq4bVl8w8vl8FAqFenfDzKyhSDoYEfnJtvmOXDOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIZUsl9giaVjSqKQjkram+nJJ+yUdS6/LUl2SviZpTNKbku4t+10bU/tjkjbO32GZmdlkKjnTvwT8SUS0Aw8AD0taCTwGvBoRbcCr6TPAWkrr4rYBm4HnoPRHAngCuB+4D3ji6h8KMzOrjWlDPyJORcQ/p/fvAaPACmAdsDM12wmsT+/XAd+Mku8Dd6RF1B8E9kfEmYg4C+wH1szp0ZiZ2ZSqGtOX1Ar8NvAa8LGIOAWlPwzAR1OzFcCJst2KqXaj+rXfsVlSQVJhfHy8mu6Zmdk0Kg59Sb8K/B3wxxHx86maTlKLKeoTCxHbIyIfEflcLldp98zMrAIVhb6kxZQC/28i4u9T+Z00bEN6PZ3qRaClbPdm4OQUdTMzq5FKZu8IGARGI+KrZZv2Aldn4GwEXiyrfz7N4nkAeDcN/7wCrJa0LF3AXZ1qZmZWI4sqaPNJ4A+BH0o6lGp/Cvw5sEdSD/AT4LNp28vAQ8AY8EvgCwARcUbSV4ADqd2XI+LMnByFmZlVRBHXDasvGPl8PgqFQr27YWbWUCQdjIj8ZNt8R66ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0Dczy5BKlkvcIem0pMNltS9JelvSofTzUNm2xyWNSXpL0oNl9TWpNibpsbk/FDMzm04lZ/rfANZMUn86Ilaln5cBJK0ENgCfSPt8XVKTpCbgWWAtsBLoTm3NGs7Q0BAdHR00NTXR0dHB0NBQvbtkVrFp18iNiO9Kaq3w960DdkfEeeC4pDHgvrRtLCJ+BCBpd2p7tOoem9XR0NAQfX19DA4O0tnZycjICD09PQB0d3fXuXdm05vNmP4WSW+m4Z9lqbYCOFHWpphqN6pfR9JmSQVJhfHx8Vl0z2zu9ff3Mzg4SFdXF4sXL6arq4vBwUH6+/vr3TWzisw09J8DfgNYBZwC/iLVNUnbmKJ+fTFie0TkIyKfy+Vm2D2z+TE6OkpnZ+eEWmdnJ6Ojo3XqkVl1ZhT6EfFORFyOiCvAX/HhEE4RaClr2gycnKJu1lDa29sZGRmZUBsZGaG9vb1OPTKrzoxCX9JdZR9/H7g6s2cvsEHSrZLuAdqA14EDQJukeyQtoXSxd+/Mu21WH319ffT09DA8PMzFixcZHh6mp6eHvr6+enfNrCLTXsiVNAR8CrhTUhF4AviUpFWUhmh+DPwRQEQckbSH0gXaS8DDEXE5/Z4twCtAE7AjIo7M+dGYzbOrF2t7e3sZHR2lvb2d/v5+X8S1hqGISYfWF4R8Ph+FQqHe3TAzayiSDkZEfrJtviPXzCxDHPpmVfLNWdbIph3TN7MP+eYsa3Qe0zerQkdHBwMDA3R1dX1QGx4epre3l8OHD0+xp1ntTDWm79A3q0JTUxPnzp1j8eLFH9QuXrzI0qVLuXz5ch17ZvYhX8g1myO+OcsanUPfrAq+OcsanS/kmlWhu7ub733ve6xdu5bz589z66238sUvftEXca1h+EzfrApDQ0O89NJL7Nu3jwsXLrBv3z5eeuklT9u0huELuWZV8OwdawSevWM2Rzx7xxqBZ++YzRHP3rFG59A3q4Jn71ij8+wdsyp49o41Op/pm1XBs3es0U0b+mnh89OSDpfVlkvaL+lYel2W6pL0NUljadH0e8v22ZjaH5O0cX4Ox2x+eWF0a3SVnOl/A1hzTe0x4NWIaANeTZ8B1lJaIrEN2ExpAXUkLae04tb9lNbTfeLqHwqzRjI6OkqxWJzwaOViseiF0a1hTBv6EfFd4Mw15XXAzvR+J7C+rP7NKPk+cEdaT/dBYH9EnImIs8B+rv9DYrbg3X333Tz66KMMDAxw7tw5BgYGePTRR7n77rvr3TWzisx0TP9jEXEKIL1+NNVXACfK2hVT7UZ1s4Zz7b0tC/leF7NrzfWFXE1Siynq1/8CabOkgqTC+Pj4nHbObLZOnjzJU089RW9vL0uXLqW3t5ennnqKkydP1rtrZhWZaei/k4ZtSK+nU70ItJS1awZOTlG/TkRsj4h8RORzudwMu2c2P9rb22lububw4cNcvnyZw4cP09zc7JuzrGHMNPT3Aldn4GwEXiyrfz7N4nkAeDcN/7wCrJa0LF3AXZ1qZg3FN2dZo5v25ixJQ8CngDslFSnNwvlzYI+kHuAnwGdT85eBh4Ax4JfAFwAi4oykrwAHUrsvR8S1F4fNFryrN2H19vYyOjpKe3s7/f39vjnLGoYfuGZmdpPxA9fMzAxw6JuZZYpD36xKQ0NDE+7I9XN3rJH4KZtmVRgaGqKvr4/BwUE6OzsZGRmhp6cHwBdzrSH4Qq5ZFbxcojUCL5doNke8XKI1As/eMZsj7e3tbNu2bcKY/rZt23xHrjUMh75ZFbq6unjyySfZtGkT7733Hps2beLJJ5+cMNxjtpB5eMesCh0dHbS1tbFv374Plktcu3Ytx44d85i+LRge3jGbI0ePHuWNN96YsFziG2+8wdGjR+vdNbOKOPTNqrBkyRK2bNkyYbnELVu2sGTJknp3zawiDn2zKly4cIGBgYEJT9kcGBjgwoUL9e6aWUV8c5ZZFVauXMn69esnPGXzc5/7HC+88EK9u2ZWEZ/pm1Whr6+PXbt2TVgjd9euXX6evjUMn+mbVcHP07dG5ymbZmY3mXmbsinpx5J+KOmQpEKqLZe0X9Kx9Los1SXpa5LGJL0p6d7ZfLdZvfgpm9bI5mJMvysiVpX9VXkMeDUi2oBX02eAtUBb+tkMPDcH321WU0NDQ2zdupX333+fiOD9999n69atDn5rGPNxIXcdsDO93wmsL6t/M0q+D9wh6a55+H6zefPII49cNz3zwoULPPLII3XqkVl1Zhv6AfxvSQclbU61j0XEKYD0+tFUXwGcKNu3mGoTSNosqSCpMD4+Psvumc2tYrHI1etgkgCICIrFYj27ZVax2Yb+JyPiXkpDNw9L+o9TtNUkteuuIkfE9ojIR0Q+l8vNsntmc2/RokXs2LGDc+fOsWPHDhYt8iQ4axyzCv2IOJleTwP/ANwHvHN12Ca9nk7Ni0BL2e7NwMnZfL9ZPVw7420hz4Azu9aMQ1/SbZJ+7ep7YDVwGNgLbEzNNgIvpvd7gc+nWTwPAO9eHQYyayRXrlxh06ZNLF26lE2bNnHlypV6d8msYrP5f+nHgH9I45qLgF0R8b8kHQD2SOoBfgJ8NrV/GXgIGAN+CXxhFt9tVhfNzc389Kc/5e233+bKlSu8/fbbLFq0iObm5np3zawiMw79iPgR8FuT1H8KfGaSegAPz/T7zBaC9evX8+yzz3LLLaX/JF+5coVz586xfv36afY0Wxj87B2zKrzwwgvcfvvttLS0cMstt9DS0sLtt9/uB65Zw3Dom1WhWCzy/PPPc/z4cS5fvszx48d5/vnnPWXTGoZD38wsQzzB2IwPb7SqxOrVq2f8Ozy90+rNZ/pmlMK4kp9du3aRy+VobW0FoLW1lVwux65duyra36zeHPpmVeju7uaZZ57htttuA+C2227jmWee8fP0rWH4efpmMyTJZ++2IM3b8/TNzKyxOPTNzDLEoW9mliEOfTOzDHHom5lliG/OspvS8uXLOXv27Lx/TzU3dc3EsmXLOHPmzLx+h2WLQ99uSmfPnr0pplPO9x8Vyx4P75iZZYhD38wsQ2oe+pLWSHpL0pikx2r9/WZmWVbTMX1JTcCzwO9SWij9gKS9EXG0lv2wm188cTt86SP17sasxRO317sLdpOp9YXc+4CxtNQiknYD6wCHvs0pbfv5TXMhN75U717YzaTWob8COFH2uQjcX95A0mZgM8DHP/7x2vXMbjo3w8yXZcuW1bsLdpOpdehP9q9wwulYRGwHtkPpKZu16JTdfG6Gs3yz+VDrC7lFoKXsczNwssZ9MDPLrFqH/gGgTdI9kpYAG4C9Ne6DmVlm1XR4JyIuSdoCvAI0ATsi4kgt+2BmlmU1fwxDRLwMvFzr7zUzM9+Ra2aWKQ59M7MMceibmWWIQ9/MLEO0kG9ikTQO/Eu9+2F2A3cC/1rvTphN4t9ERG6yDQs69M0WMkmFiMjXux9m1fDwjplZhjj0zcwyxKFvNnPb690Bs2p5TN/MLEN8pm9mliEOfTOzDHHom1VJ0g5JpyUdrndfzKrl0Der3jeANfXuhNlMOPTNqhQR3wXO1LsfZjPh0DczyxCHvplZhjj0zcwyxKFvZpYhDn2zKkkaAv4J+HeSipJ66t0ns0r5MQxmZhniM30zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMuT/A4aKm17f+eY+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum annotations by an annotator:  5\n",
      "Maximum annotations by an annotator:  3993\n",
      "Mean annotations by an annotator:  136.67980295566502\n"
     ]
    }
   ],
   "source": [
    "#graphics and distribution? what is T_data\n",
    "N_ann = np.sum(y_obs != -1,axis=1) #distribucion de anotaciones con este valor\n",
    "\n",
    "sns.countplot(N_ann)\n",
    "plt.show()\n",
    "print(\"Minimum annotations in a example: \",N_ann.min())\n",
    "print(\"Maximum annotations in a example: \",N_ann.max())\n",
    "print(\"T data (expected value): \",N_ann.mean())\n",
    "\n",
    "print(\"Graphics of T weights\")\n",
    "plt.hist(T_weights)\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(T_weights)\n",
    "plt.show()\n",
    "print(\"Minimum annotations by an annotator: \",T_weights.min())\n",
    "print(\"Maximum annotations by an annotator: \",T_weights.max())\n",
    "print(\"Mean annotations by an annotator: \",T_weights.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Matrix representation of both scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual representation shape (N,T,K)=  (4999, 203, 2)\n",
      "Global representation shape (N,K)=  (4999, 2)\n"
     ]
    }
   ],
   "source": [
    "from codeE.representation import set_representation\n",
    "\n",
    "y_obs_categorical = set_representation(y_obs,'onehot') \n",
    "print(\"Individual representation shape (N,T,K)= \",y_obs_categorical.shape)\n",
    "\n",
    "r_obs = set_representation(y_obs,\"global\")\n",
    "print(\"Global representation shape (N,K)= \",r_obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 5],\n",
       "       [5, 0],\n",
       "       [4, 2],\n",
       "       ...,\n",
       "       [2, 4],\n",
       "       [1, 4],\n",
       "       [3, 2]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Real Confusion matrices\n",
    "Generate the individual and global confusion matrices based on the sampled annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual matrix shape (T,K,K)=  (203, 2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.7059, 0.2941],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.9483, 0.0517],\n",
       "        [0.1373, 0.8627]],\n",
       "\n",
       "       [[0.9756, 0.0244],\n",
       "        [0.1053, 0.8947]],\n",
       "\n",
       "       [[0.9306, 0.0694],\n",
       "        [0.0763, 0.9237]],\n",
       "\n",
       "       [[0.9401, 0.0599],\n",
       "        [0.2284, 0.7716]],\n",
       "\n",
       "       [[0.6469, 0.3531],\n",
       "        [0.1608, 0.8392]],\n",
       "\n",
       "       [[0.9344, 0.0656],\n",
       "        [0.0792, 0.9208]],\n",
       "\n",
       "       [[0.8919, 0.1081],\n",
       "        [0.1127, 0.8873]],\n",
       "\n",
       "       [[0.625 , 0.375 ],\n",
       "        [0.381 , 0.619 ]],\n",
       "\n",
       "       [[0.8139, 0.1861],\n",
       "        [0.1332, 0.8668]],\n",
       "\n",
       "       [[0.8372, 0.1628],\n",
       "        [0.2289, 0.7711]],\n",
       "\n",
       "       [[0.8983, 0.1017],\n",
       "        [0.06  , 0.94  ]],\n",
       "\n",
       "       [[0.9123, 0.0877],\n",
       "        [0.1466, 0.8534]],\n",
       "\n",
       "       [[0.9301, 0.0699],\n",
       "        [0.1252, 0.8748]],\n",
       "\n",
       "       [[0.7703, 0.2297],\n",
       "        [0.1429, 0.8571]],\n",
       "\n",
       "       [[0.9327, 0.0673],\n",
       "        [0.1178, 0.8822]],\n",
       "\n",
       "       [[0.9286, 0.0714],\n",
       "        [0.0909, 0.9091]],\n",
       "\n",
       "       [[0.9383, 0.0617],\n",
       "        [0.0678, 0.9322]],\n",
       "\n",
       "       [[0.4615, 0.5385],\n",
       "        [0.25  , 0.75  ]],\n",
       "\n",
       "       [[0.7164, 0.2836],\n",
       "        [0.1176, 0.8824]],\n",
       "\n",
       "       [[0.7436, 0.2564],\n",
       "        [0.0779, 0.9221]],\n",
       "\n",
       "       [[0.7917, 0.2083],\n",
       "        [0.3048, 0.6952]],\n",
       "\n",
       "       [[0.7347, 0.2653],\n",
       "        [0.3084, 0.6916]],\n",
       "\n",
       "       [[0.375 , 0.625 ],\n",
       "        [0.2857, 0.7143]],\n",
       "\n",
       "       [[0.8393, 0.1607],\n",
       "        [0.0847, 0.9153]],\n",
       "\n",
       "       [[0.7292, 0.2708],\n",
       "        [0.2097, 0.7903]],\n",
       "\n",
       "       [[0.9481, 0.0519],\n",
       "        [0.1029, 0.8971]],\n",
       "\n",
       "       [[0.754 , 0.246 ],\n",
       "        [0.112 , 0.888 ]],\n",
       "\n",
       "       [[0.9167, 0.0833],\n",
       "        [0.0769, 0.9231]],\n",
       "\n",
       "       [[0.5714, 0.4286],\n",
       "        [0.1875, 0.8125]],\n",
       "\n",
       "       [[0.7742, 0.2258],\n",
       "        [0.069 , 0.931 ]],\n",
       "\n",
       "       [[0.7444, 0.2556],\n",
       "        [0.2095, 0.7905]],\n",
       "\n",
       "       [[0.92  , 0.08  ],\n",
       "        [0.25  , 0.75  ]],\n",
       "\n",
       "       [[0.8158, 0.1842],\n",
       "        [0.1622, 0.8378]],\n",
       "\n",
       "       [[0.3864, 0.6136],\n",
       "        [0.1839, 0.8161]],\n",
       "\n",
       "       [[0.4882, 0.5118],\n",
       "        [0.1429, 0.8571]],\n",
       "\n",
       "       [[0.6944, 0.3056],\n",
       "        [0.1471, 0.8529]],\n",
       "\n",
       "       [[0.913 , 0.087 ],\n",
       "        [0.0909, 0.9091]],\n",
       "\n",
       "       [[0.9478, 0.0522],\n",
       "        [0.0574, 0.9426]],\n",
       "\n",
       "       [[0.9032, 0.0968],\n",
       "        [0.1034, 0.8966]],\n",
       "\n",
       "       [[0.9394, 0.0606],\n",
       "        [0.0909, 0.9091]],\n",
       "\n",
       "       [[0.9091, 0.0909],\n",
       "        [0.2105, 0.7895]],\n",
       "\n",
       "       [[0.375 , 0.625 ],\n",
       "        [0.1429, 0.8571]],\n",
       "\n",
       "       [[0.8571, 0.1429],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.7222, 0.2778],\n",
       "        [0.1111, 0.8889]],\n",
       "\n",
       "       [[0.9125, 0.0875],\n",
       "        [0.1286, 0.8714]],\n",
       "\n",
       "       [[0.6471, 0.3529],\n",
       "        [0.2222, 0.7778]],\n",
       "\n",
       "       [[0.9091, 0.0909],\n",
       "        [0.2857, 0.7143]],\n",
       "\n",
       "       [[0.8889, 0.1111],\n",
       "        [0.1084, 0.8916]],\n",
       "\n",
       "       [[0.8875, 0.1125],\n",
       "        [0.15  , 0.85  ]],\n",
       "\n",
       "       [[0.8   , 0.2   ],\n",
       "        [0.28  , 0.72  ]],\n",
       "\n",
       "       [[0.9032, 0.0968],\n",
       "        [0.2647, 0.7353]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.8571, 0.1429],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.7143, 0.2857],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.7333, 0.2667],\n",
       "        [0.25  , 0.75  ]],\n",
       "\n",
       "       [[0.3636, 0.6364],\n",
       "        [0.375 , 0.625 ]],\n",
       "\n",
       "       [[0.6154, 0.3846],\n",
       "        [0.1364, 0.8636]],\n",
       "\n",
       "       [[0.9231, 0.0769],\n",
       "        [0.2727, 0.7273]],\n",
       "\n",
       "       [[0.    , 1.    ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.1111, 0.8889]],\n",
       "\n",
       "       [[0.6   , 0.4   ],\n",
       "        [0.4   , 0.6   ]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.1579, 0.8421]],\n",
       "\n",
       "       [[0.72  , 0.28  ],\n",
       "        [0.2667, 0.7333]],\n",
       "\n",
       "       [[0.2222, 0.7778],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.0714, 0.9286]],\n",
       "\n",
       "       [[0.3333, 0.6667],\n",
       "        [0.5   , 0.5   ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.3333, 0.6667],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[0.8   , 0.2   ],\n",
       "        [0.2   , 0.8   ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.6667, 0.3333]],\n",
       "\n",
       "       [[0.7143, 0.2857],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.25  , 0.75  ],\n",
       "        [0.1429, 0.8571]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.3333, 0.6667],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.25  , 0.75  ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.674 , 0.326 ],\n",
       "        [0.1571, 0.8429]],\n",
       "\n",
       "       [[0.8529, 0.1471],\n",
       "        [0.2836, 0.7164]],\n",
       "\n",
       "       [[0.7647, 0.2353],\n",
       "        [0.1111, 0.8889]],\n",
       "\n",
       "       [[0.75  , 0.25  ],\n",
       "        [0.1667, 0.8333]],\n",
       "\n",
       "       [[0.963 , 0.037 ],\n",
       "        [0.1429, 0.8571]],\n",
       "\n",
       "       [[0.4524, 0.5476],\n",
       "        [0.1772, 0.8228]],\n",
       "\n",
       "       [[0.8777, 0.1223],\n",
       "        [0.0541, 0.9459]],\n",
       "\n",
       "       [[0.471 , 0.529 ],\n",
       "        [0.2368, 0.7632]],\n",
       "\n",
       "       [[0.8841, 0.1159],\n",
       "        [0.1207, 0.8793]],\n",
       "\n",
       "       [[0.9122, 0.0878],\n",
       "        [0.1338, 0.8662]],\n",
       "\n",
       "       [[0.8276, 0.1724],\n",
       "        [0.0769, 0.9231]],\n",
       "\n",
       "       [[0.8878, 0.1122],\n",
       "        [0.1609, 0.8391]],\n",
       "\n",
       "       [[0.3192, 0.6808],\n",
       "        [0.2083, 0.7917]],\n",
       "\n",
       "       [[0.877 , 0.123 ],\n",
       "        [0.1525, 0.8475]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.0667, 0.9333]],\n",
       "\n",
       "       [[0.7439, 0.2561],\n",
       "        [0.1111, 0.8889]],\n",
       "\n",
       "       [[0.9181, 0.0819],\n",
       "        [0.0798, 0.9202]],\n",
       "\n",
       "       [[0.8987, 0.1013],\n",
       "        [0.1   , 0.9   ]],\n",
       "\n",
       "       [[0.7887, 0.2113],\n",
       "        [0.1014, 0.8986]],\n",
       "\n",
       "       [[0.5102, 0.4898],\n",
       "        [0.2292, 0.7708]],\n",
       "\n",
       "       [[0.8667, 0.1333],\n",
       "        [0.1   , 0.9   ]],\n",
       "\n",
       "       [[0.9062, 0.0938],\n",
       "        [0.0741, 0.9259]],\n",
       "\n",
       "       [[0.9308, 0.0692],\n",
       "        [0.1187, 0.8813]],\n",
       "\n",
       "       [[0.9739, 0.0261],\n",
       "        [0.0837, 0.9163]],\n",
       "\n",
       "       [[0.633 , 0.367 ],\n",
       "        [0.1354, 0.8646]],\n",
       "\n",
       "       [[0.9574, 0.0426],\n",
       "        [0.0407, 0.9593]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.1111, 0.8889]],\n",
       "\n",
       "       [[0.9444, 0.0556],\n",
       "        [0.3529, 0.6471]],\n",
       "\n",
       "       [[0.875 , 0.125 ],\n",
       "        [0.087 , 0.913 ]],\n",
       "\n",
       "       [[0.7015, 0.2985],\n",
       "        [0.1528, 0.8472]],\n",
       "\n",
       "       [[0.9643, 0.0357],\n",
       "        [0.1875, 0.8125]],\n",
       "\n",
       "       [[0.8254, 0.1746],\n",
       "        [0.0351, 0.9649]],\n",
       "\n",
       "       [[0.96  , 0.04  ],\n",
       "        [0.1143, 0.8857]],\n",
       "\n",
       "       [[0.9383, 0.0617],\n",
       "        [0.1186, 0.8814]],\n",
       "\n",
       "       [[0.8367, 0.1633],\n",
       "        [0.0714, 0.9286]],\n",
       "\n",
       "       [[0.8913, 0.1087],\n",
       "        [0.0794, 0.9206]],\n",
       "\n",
       "       [[0.3766, 0.6234],\n",
       "        [0.3864, 0.6136]],\n",
       "\n",
       "       [[0.7969, 0.2031],\n",
       "        [0.0893, 0.9107]],\n",
       "\n",
       "       [[0.9167, 0.0833],\n",
       "        [0.2308, 0.7692]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.7941, 0.2059],\n",
       "        [0.4286, 0.5714]],\n",
       "\n",
       "       [[0.9   , 0.1   ],\n",
       "        [0.0678, 0.9322]],\n",
       "\n",
       "       [[0.5263, 0.4737],\n",
       "        [0.4375, 0.5625]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.125 , 0.875 ]],\n",
       "\n",
       "       [[0.9038, 0.0962],\n",
       "        [0.1235, 0.8765]],\n",
       "\n",
       "       [[0.9483, 0.0517],\n",
       "        [0.2131, 0.7869]],\n",
       "\n",
       "       [[0.8571, 0.1429],\n",
       "        [0.125 , 0.875 ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.2   , 0.8   ]],\n",
       "\n",
       "       [[0.6579, 0.3421],\n",
       "        [0.1622, 0.8378]],\n",
       "\n",
       "       [[0.8889, 0.1111],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.875 , 0.125 ],\n",
       "        [0.2195, 0.7805]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.9767, 0.0233],\n",
       "        [0.1081, 0.8919]],\n",
       "\n",
       "       [[0.9474, 0.0526],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.8636, 0.1364],\n",
       "        [0.0714, 0.9286]],\n",
       "\n",
       "       [[0.8788, 0.1212],\n",
       "        [0.2857, 0.7143]],\n",
       "\n",
       "       [[0.75  , 0.25  ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.0714, 0.9286]],\n",
       "\n",
       "       [[0.    , 1.    ],\n",
       "        [0.1667, 0.8333]],\n",
       "\n",
       "       [[0.7692, 0.2308],\n",
       "        [0.0909, 0.9091]],\n",
       "\n",
       "       [[0.3333, 0.6667],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.8333, 0.1667],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.8333, 0.1667],\n",
       "        [0.1875, 0.8125]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.7885, 0.2115],\n",
       "        [0.1061, 0.8939]],\n",
       "\n",
       "       [[0.8857, 0.1143],\n",
       "        [0.12  , 0.88  ]],\n",
       "\n",
       "       [[0.375 , 0.625 ],\n",
       "        [0.2857, 0.7143]],\n",
       "\n",
       "       [[0.8   , 0.2   ],\n",
       "        [0.4   , 0.6   ]],\n",
       "\n",
       "       [[0.8   , 0.2   ],\n",
       "        [0.2222, 0.7778]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.1905, 0.8095]],\n",
       "\n",
       "       [[0.7568, 0.2432],\n",
       "        [0.3478, 0.6522]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.2857, 0.7143]],\n",
       "\n",
       "       [[0.8   , 0.2   ],\n",
       "        [0.2   , 0.8   ]],\n",
       "\n",
       "       [[0.8   , 0.2   ],\n",
       "        [0.2   , 0.8   ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.5   , 0.5   ]],\n",
       "\n",
       "       [[0.5714, 0.4286],\n",
       "        [0.5   , 0.5   ]],\n",
       "\n",
       "       [[0.3333, 0.6667],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.    , 1.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.1111, 0.8889]],\n",
       "\n",
       "       [[0.    , 1.    ],\n",
       "        [0.5   , 0.5   ]],\n",
       "\n",
       "       [[0.4   , 0.6   ],\n",
       "        [0.2   , 0.8   ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.8333, 0.1667],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.25  , 0.75  ],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.5   , 0.5   ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.    , 1.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.6   , 0.4   ],\n",
       "        [0.2   , 0.8   ]],\n",
       "\n",
       "       [[0.25  , 0.75  ],\n",
       "        [1.    , 0.    ]],\n",
       "\n",
       "       [[0.6   , 0.4   ],\n",
       "        [0.5   , 0.5   ]],\n",
       "\n",
       "       [[1.    , 0.    ],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.25  , 0.75  ]],\n",
       "\n",
       "       [[0.3333, 0.6667],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.    , 1.    ],\n",
       "        [0.3333, 0.6667]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.6667, 0.3333],\n",
       "        [0.    , 1.    ]],\n",
       "\n",
       "       [[0.4913, 0.5087],\n",
       "        [0.5183, 0.4817]],\n",
       "\n",
       "       [[0.5942, 0.4058],\n",
       "        [0.3934, 0.6066]],\n",
       "\n",
       "       [[0.5417, 0.4583],\n",
       "        [0.6265, 0.3735]],\n",
       "\n",
       "       [[0.506 , 0.494 ],\n",
       "        [0.4098, 0.5902]],\n",
       "\n",
       "       [[0.5873, 0.4127],\n",
       "        [0.4464, 0.5536]],\n",
       "\n",
       "       [[0.5424, 0.4576],\n",
       "        [0.4937, 0.5063]],\n",
       "\n",
       "       [[0.6533, 0.3467],\n",
       "        [0.3571, 0.6429]],\n",
       "\n",
       "       [[0.4194, 0.5806],\n",
       "        [0.6133, 0.3867]],\n",
       "\n",
       "       [[0.8837, 0.1163],\n",
       "        [0.0845, 0.9155]],\n",
       "\n",
       "       [[0.9367, 0.0633],\n",
       "        [0.0521, 0.9479]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codeE.utils import generate_Individual_conf\n",
    "\n",
    "conf_matrix_I = generate_Individual_conf(Z_train, y_obs_categorical)\n",
    "print(\"Individual matrix shape (T,K,K)= \",conf_matrix_I.shape)\n",
    "conf_matrix_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global matrix shape (K,K)=  (2, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from codeE.utils import generate_Global_conf\n",
    "\n",
    "#confe_matrix_G = generate_Global_conf(Z_train, y_obs_categorical)\n",
    "confe_matrix_G = generate_Global_conf(Z_train, r_obs)\n",
    "print(\"Global matrix shape (K,K)= \",confe_matrix_G.shape)\n",
    "\n",
    "from codeE.utils import plot_confusion_matrix\n",
    "plot_confusion_matrix(confe_matrix_G, [\"negative\", \"positive\"], title= \"Global Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta Convergence criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.learning_models import LogisticRegression_Sklearn,LogisticRegression_Keras,MLP_Keras\n",
    "#deep learning\n",
    "from codeE.learning_models import default_CNN,default_RNN,CNN_simple, RNN_simple, Clonable_Model\n",
    "\n",
    "from codeE.utils import EarlyStopRelative\n",
    "ourCallback = EarlyStopRelative(monitor='loss',patience=1,min_delta=TOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Bound Model -- ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_train_onehot = keras.utils.to_categorical(Z_train)\n",
    "Kl = Z_train_onehot.shape[1]\n",
    "\n",
    "model_UB = default_RNN_text(max_L, Kl, embed_M=embedding_matrix)\n",
    "model_UB.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist = model_UB.fit(X_train,Z_train_onehot,epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained IDeal Model, Epochs to converge =\",len(hist.epoch))\n",
    "clone_UB = Clonable_Model(model_UB)\n",
    "Z_train_pred = model_UB.predict_classes(X_train)\n",
    "Z_test_pred = model_UB.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"],label=\"train\")\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeE.evaluation import accuracy_model\n",
    "print(\"Train accuracy of model =\", accuracy_model(model_UB, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(model_UB, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from codeE.evaluation import f1score_model\n",
    "print(\"Train accuracy of model =\", f1score_model(model_UB, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", f1score_model(model_UB, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation methods (without predictive model)\n",
    "* Majority Voting (MV)\n",
    "* Weighted Majority Voting\n",
    "* Dawid and Skene (DS): with inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.methods import LabelAggregation\n",
    "label_A = LabelAggregation(scenario=\"global\")\n",
    "\n",
    "mv_soft = label_A.infer(  r_obs, 'softMV')\n",
    "mv_hard = label_A.predict(r_obs, 'hardMV')\n",
    "mv_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.methods import LabelAggregation\n",
    "label_A = LabelAggregation(scenario=\"individual\")\n",
    "\n",
    "mv_soft = label_A.infer(  y_obs_categorical, 'softMV')\n",
    "mv_hard = label_A.predict(y_obs_categorical, 'hardMV')\n",
    "mv_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACC MV on train:\",np.mean(mv_hard==Z_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate confusion matrix to understand MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeE.utils import generate_confusionM\n",
    "prob_Yz = generate_confusionM(mv_soft, r_obs) #confusion matrix of all annotators\n",
    "\n",
    "from codeE.utils import plot_confusion_matrix\n",
    "plot_confusion_matrix(prob_Yz, np.arange(8), title= \"soft-MV confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_Yz = generate_confusionM(mv_hard, r_obs) #confusion matrix of all annotators\n",
    "plot_confusion_matrix(prob_Yz, np.arange(8), title= \"hard-MV confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to compare the estimation of confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeE.utils import compare_conf_mats\n",
    "compare_conf_mats(prob_Yz, true_conf_mat=confe_matrix_G, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeE.evaluation import D_JS, D_KL, D_NormF\n",
    "print(\"Global D (based on Jensen Shannon) =\",D_JS(confe_matrix_G, prob_Yz))\n",
    "print(\"Global D (based on normalized Frobenius) =\",D_NormF(confe_matrix_G, prob_Yz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeE.methods import LabelAggregation\n",
    "label_A = LabelAggregation(scenario=\"individual\")\n",
    "\n",
    "Wmv_soft = label_A.infer(y_obs_categorical, 'softMV', weights=T_weights)\n",
    "Wmv_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACC MV on train:\",np.mean(Wmv_soft.argmax(axis=-1)==Z_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dawid and Skene model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.methods import LabelInference_EM as DS\n",
    "\n",
    "DS_model = DS(init_Z='softmv') \n",
    "#DS_model = DS(init_Z='softmv', priors=\"None\", fast=False) \n",
    "    \n",
    "# if you want you can initialize step E forcing some method\n",
    "#DS_model.init_E(y_obs_categorical)\n",
    "#DS_model.get_qestimation()\n",
    "\n",
    "hist = DS_model.fit(y_obs_categorical, max_iter=EPOCHS_BASE, tolerance=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p(z) = \",DS_model.get_marginalZ())\n",
    "\n",
    "ds_labels = DS_model.infer() #could infer/predict on the trainint set only\n",
    "ds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACC D&S on train:\",np.mean(ds_labels.argmax(axis=1)==Z_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_Yzt = DS_model.get_confusionM() # estimate of conf_matrix_I\n",
    "\n",
    "from codeE.evaluation import Individual_D, D_JS, D_NormF\n",
    "print(\"Individual D_JS = \",Individual_D(conf_matrix_I, prob_Yzt, D=D_JS))\n",
    "print(\"Individual D_NormF = \",Individual_D(conf_matrix_I, prob_Yzt, D=D_NormF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Phase\n",
    "train a predictive model over the inference/aggregation label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeE.evaluation import accuracy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mvsoft = clone_UB.get_model()\n",
    "model_mvsoft.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist=model_mvsoft.fit(Xstd_train, mv_soft, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained model over soft-MV, Epochs to converge =\",len(hist.epoch))\n",
    "\n",
    "#Z_train_pred = model_mvsoft.predict_classes(Xstd_train)\n",
    "#Z_test_pred = model_mvsoft.predict_classes(Xstd_test)\n",
    "\n",
    "print(\"Train accuracy of model =\", accuracy_model(model_mvsoft, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(model_mvsoft, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_hard_onehot = keras.utils.to_categorical(mv_hard, num_classes=Kl)\n",
    "mv_hard_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mvhard = clone_UB.get_model()\n",
    "model_mvhard.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist=model_mvhard.fit(Xstd_train, mv_hard_onehot, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained model over hard-MV, Epochs to converge =\",len(hist.epoch))\n",
    "\n",
    "#Z_train_pred = model_mvhard.predict_classes(Xstd_train)\n",
    "#Z_test_pred = model_mvhard.predict_classes(Xstd_test)\n",
    "print(\"Train accuracy of model =\", accuracy_model(model_mvhard, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(model_mvhard, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ds = clone_UB.get_model()\n",
    "model_ds.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist=model_ds.fit(Xstd_train, ds_labels, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained model over D&S, Epochs to converge =\",len(hist.epoch))\n",
    "\n",
    "#Z_train_pred = model_ds.predict_classes(Xstd_train)\n",
    "#Z_test_pred = model_ds.predict_classes(Xstd_test)\n",
    "\n",
    "print(\"Train accuracy of model =\", accuracy_model(model_ds, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(model_ds, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raykar Model (joint predict model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_R = clone_UB.get_model()\n",
    "model_R.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.methods import ModelInference_EM as Raykar\n",
    "R_model = Raykar(init_Z=\"softmv\")\n",
    "#R_model = Raykar(init_Z=\"softmv\", priors='laplace', n_init_Z=3)\n",
    "\n",
    "args = {'epochs':1, 'batch_size':BATCH_SIZE, 'optimizer':OPT}\n",
    "R_model.set_model(model_R, **args)\n",
    "\n",
    "# if you want you can initialize step E forcing some method\n",
    "#R_model.init_E(y_obs_categorical, method=\"hardmv\")\n",
    "#R_model.get_qestimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logL_hists,i_r = R_model.multiples_run(20, Xstd_train,y_obs_categorical,\n",
    "#                                        max_iter=EPOCHS_BASE, tolerance=TOL)\n",
    "\n",
    "R_model.fit(Xstd_train, y_obs_categorical, runs=20, max_iter=EPOCHS_BASE, tolerance=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): \n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raykar_fx = R_model.get_basemodel()\n",
    "\n",
    "from codeE.evaluation import accuracy_model\n",
    "print(\"Train accuracy of model =\", accuracy_model(raykar_fx, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(raykar_fx, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_Yzt = R_model.get_confusionM() # estimate of conf_matrix_I\n",
    "\n",
    "from codeE.evaluation import Individual_D, D_JS, D_NormF\n",
    "print(\"Individual D_JS = \",Individual_D(conf_matrix_I, prob_Yzt, D=D_JS))\n",
    "print(\"Individual D_NormF = \",Individual_D(conf_matrix_I, prob_Yzt, D=D_NormF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_Yz = prob_Yzt.mean(axis=0)\n",
    "from codeE.evaluation import D_JS, D_KL, D_NormF\n",
    "print(\"Global D (based on Jensen Shannon) =\",D_JS(confe_matrix_G, prob_Yz))\n",
    "print(\"Global D (based on normalized Frobenius) =\",D_NormF(confe_matrix_G, prob_Yz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#how good estimate the annotations ?\n",
    "prob_Y_xt = R_model.get_predictions_annot(Xstd_train)\n",
    "- np.sum(np.sum(y_obs_categorical * np.log(prob_Y_xt +1e-7 ), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Proposed - CMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_seted = 3\n",
    "\n",
    "aux_model = clone_UB.get_model()\n",
    "aux_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.methods import CMM\n",
    "CMM_model = CMM(M=M_seted) \n",
    "#CMM_model = CMM(M=M_seted, init_Z='softmv', n_init_Z=3, priors=0) \n",
    "\n",
    "args = {'epochs':1, 'batch_size':BATCH_SIZE, 'optimizer':OPT}\n",
    "CMM_model.set_model(aux_model, **args)\n",
    "\n",
    "# if you want you can initialize step E forcing some method\n",
    "#CMM_model.init_E(r_obs, method=\"hardmv\")\n",
    "#CMM_model.get_qestimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logL_hists,i_r = CMM_model.multiples_run(20,Xstd_train,r_obs,\n",
    "#                                               max_iter=EPOCHS_BASE,tolerance=TOL)\n",
    "\n",
    "CMM_model.fit(Xstd_train, r_obs, runs =20,max_iter=EPOCHS_BASE,tolerance=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): #logL_hists\n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmm_fx = CMM_model.get_basemodel()\n",
    "\n",
    "from codeE.evaluation import accuracy_model\n",
    "print(\"Train accuracy of model =\", accuracy_model(cmm_fx, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(cmm_fx, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_Yz = CMM_model.get_global_confusionM()\n",
    "\n",
    "from codeE.evaluation import D_JS, D_KL, D_NormF\n",
    "print(\"Global D (based on Jensen Shannon) =\",D_JS(confe_matrix_G, prob_Yz))\n",
    "print(\"Global D (based on normalized Frobenius) =\",D_NormF(confe_matrix_G, prob_Yz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p(g) =\",CMM_model.get_alpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = CMM_model.get_confusionM()\n",
    "for i in range(len(B)):\n",
    "    plot_confusion_matrix(B[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With priors= \"laplace\"\n",
    "smooth confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): #logL_hists\n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p(g) =\",CMM_model.get_alpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = CMM_model.get_confusionM()\n",
    "for i in range(len(B)):\n",
    "    plot_confusion_matrix(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## usar las otras funciones parao btener grupos de anotadoras.. en visualizacion!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_Yzt = []\n",
    "for t in range(y_obs.shape[1]):\n",
    "    conf = CMM_model.get_ann_confusionM(Xstd_train, y_obs[:,t])\n",
    "    \n",
    "    prob_Yzt.append(conf)\n",
    "prob_Yzt = np.asarray(prob_Yzt)\n",
    "prob_Yzt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Proposed - C-MoA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliar representation with variable number of annotations per annotator and identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_var, A_idx_var = set_representation(y_obs,\"onehotvar\")\n",
    "print(\"Individual sparse representation, variable shape (N,)= \",y_cat_var.shape)\n",
    "K = y_cat_var[0].shape[1]\n",
    "print(\"one-hot vectors of K-dimensions, K=\",K)\n",
    "y_cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_seted = 3\n",
    "\n",
    "aux_model = clone_UB.get_model()\n",
    "aux_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed annotators representation (non trainable embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T= np.concatenate(A_idx_var).max() +1\n",
    "A_rep = np.zeros((T, K))\n",
    "for i in range(N):\n",
    "    for l, t_idx in enumerate(A_idx_var[i]):\n",
    "        obs_t = y_cat_var[i][l].argmax(axis=-1)\n",
    "        A_rep[t_idx, obs_t] += 1\n",
    "print(\"shape of annotator representation (T, R_t)=\", A_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "group_model = Sequential()\n",
    "group_model.add(Embedding(T, K,input_length=1, \n",
    "                         trainable=False,weights=[A_rep]))\n",
    "#                         trainable=True))\n",
    "group_model.add(Reshape([K]))\n",
    "group_model.add(Dense(K*M_seted, activation='relu'))\n",
    "group_model.add(Dense(M_seted, activation='softmax'))\n",
    "group_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from codeE.methods import CMOA\n",
    "CMOA_model = CMOA(M=M_seted) \n",
    "#CMOA_model = CMOA(M=M_seted, init_Z='softmv', n_init_Z=0, n_init_G=0, priors=1) \n",
    "\n",
    "args = {'epochs':1, 'batch_size':BATCH_SIZE, 'optimizer':OPT}\n",
    "CMOA_model.set_model(aux_model, ann_model=group_model, **args)\n",
    "#CMOA_model.set_model(group_model) #you also can set it manually\n",
    "\n",
    "# if you want you can initialize step E forcing some method\n",
    "#CMOA_model.init_E(y_cat_var, A_idx_var, method=\"hardmv\")\n",
    "#CMOA_model.get_qestimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logL_hists,i_r = CMOA_model.multiples_run(20,Xstd_train,y_cat_var, A_idx_var, \n",
    "#                                   max_iter=EPOCHS_BASE,tolerance=TOL) \n",
    "\n",
    "CMOA_model.fit(Xstd_train, y_cat_var, A_idx_var, runs = 20,max_iter=EPOCHS_BASE,tolerance=TOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): #logL_hists\n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmoaK_fx = CMOA_model.get_basemodel()\n",
    "\n",
    "from codeE.evaluation import accuracy_model\n",
    "print(\"Train accuracy of model =\", accuracy_model(cmoaK_fx, Xstd_train, Z_train))\n",
    "print(\"Test accuracy of model =\", accuracy_model(cmoaK_fx, Xstd_test, Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = np.unique(np.concatenate(A_idx_var)).reshape(-1,1)\n",
    "prob_Yzt = CMOA_model.get_ann_confusionM(A) # estimate of conf_matrix_I\n",
    "\n",
    "from codeE.evaluation import Individual_D, D_JS, D_NormF\n",
    "print(\"Individual D_JS = \",Individual_D(conf_matrix_I, prob_Yzt, D=D_JS))\n",
    "print(\"Individual D_NormF = \",Individual_D(conf_matrix_I, prob_Yzt, D=D_NormF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = CMOA_model.get_confusionM()\n",
    "for i in range(len(B)):\n",
    "    plot_confusion_matrix(B[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With priors= \"laplace\"\n",
    "smooth confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = CMOA_model.get_confusionM()\n",
    "for i in range(len(B)):\n",
    "    plot_confusion_matrix(B[i])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:newpy3_tf1]",
   "language": "python",
   "name": "conda-env-newpy3_tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
